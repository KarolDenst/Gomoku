{"cells":[{"cell_type":"code","execution_count":43,"metadata":{"id":"Kwd8Gfnhj87B"},"outputs":[],"source":["import numpy as np\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","from tqdm.notebook import trange\n","import random\n","import os\n","\n","torch.manual_seed(0)\n","\n","EMPTY = 0\n","PLAYER1 = 1\n","PLAYER2 = -1\n","BOARD_SIZE = 10"]},{"cell_type":"code","execution_count":44,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":20008,"status":"ok","timestamp":1716840587885,"user":{"displayName":"Karol Denst","userId":"00469011533726302230"},"user_tz":-120},"id":"K6CVkWhjks5s","outputId":"1b0c2df3-9fc7-4a0b-ed22-29263d2dfea3"},"outputs":[],"source":["def in_colab():\n","    try:\n","        import google.colab\n","        return True\n","    except ImportError:\n","        return False\n","\n","if in_colab():\n","    from google.colab import drive\n","    drive.mount('/content/drive')\n","    base_path = '/content/drive/My Drive/Colab Notebooks'\n","else:\n","    base_path = '.'\n","\n","model_path = os.path.join(base_path, 'alpha_gomoku/model')\n","optimizer_path = os.path.join(base_path, 'alpha_gomoku/optimizer')\n","\n","os.makedirs(model_path, exist_ok=True)\n","os.makedirs(optimizer_path, exist_ok=True)"]},{"cell_type":"code","execution_count":45,"metadata":{"id":"6I9WV8suj87C"},"outputs":[],"source":["class Gomoku:\n","    def __init__(self, size=15):\n","        self.size = size\n","\n","    def get_initial_state(self):\n","        return np.zeros((self.size, self.size)).astype(np.int8)\n","\n","    def get_next_state(self, state, action, player):\n","        row = action // self.size\n","        col = action % self.size\n","        if state[row, col] != EMPTY:\n","            raise ValueError(\"Invalid action\")\n","        state[row, col] = player\n","        return state\n","\n","    def get_moves(self, state):\n","        return (state.reshape(-1) == EMPTY).astype(np.uint8)\n","\n","    def check_win(self, state, action):\n","        if action is None:\n","            return False\n","\n","        row = action // self.size\n","        col = action % self.size\n","        player = state[row, col]\n","        if player == EMPTY:\n","            return False\n","\n","        directions = [(1, 0), (0, 1), (1, 1), (1, -1)]\n","\n","        for dr, dc in directions:\n","            count = 1\n","\n","            # Create an array of indices for positive direction\n","            indices = np.array([(row + i * dr, col + i * dc) for i in range(1, 5)])\n","            valid_indices = (indices[:, 0] >= 0) & (indices[:, 0] < self.size) & (indices[:, 1] >= 0) & (indices[:, 1] < self.size)\n","            valid_indices = indices[valid_indices]\n","\n","            count += np.sum(state[valid_indices[:, 0], valid_indices[:, 1]] == player)\n","\n","            # Create an array of indices for negative direction\n","            indices = np.array([(row - i * dr, col - i * dc) for i in range(1, 5)])\n","            valid_indices = (indices[:, 0] >= 0) & (indices[:, 0] < self.size) & (indices[:, 1] >= 0) & (indices[:, 1] < self.size)\n","            valid_indices = indices[valid_indices]\n","\n","            count += np.sum(state[valid_indices[:, 0], valid_indices[:, 1]] == player)\n","\n","            if count >= 5:\n","                return True\n","\n","        return False\n","\n","    def get_value_and_terminated(self, state, action):\n","        if self.check_win(state, action):\n","            return 1, True\n","        if np.sum(state == EMPTY) == 0:\n","            return 0, True\n","        return 0, False\n","\n","    def get_opponent(self, player):\n","        return PLAYER1 if player == PLAYER2 else PLAYER2\n","\n","    def get_opponent_value(self, player):\n","        return -player\n","\n","    def change_perspective(self, state, player):\n","        return state * player\n","\n","    def get_encoded_state(self, state):\n","        encoded_state = np.stack(\n","            (state == PLAYER1, state == PLAYER2, state == EMPTY)\n","        ).astype(np.float32)\n","\n","        if len(state.shape) == 3:\n","            encoded_state = np.swapaxes(encoded_state, 0, 1)\n","        \n","        return encoded_state\n","\n","\n","    def print(self, state):\n","        board_str = ''\n","        for row in range(self.size):\n","            row_str = ' '.join(str(state[row, col]) if state[row, col] != EMPTY else '.' for col in range(self.size))\n","            board_str += row_str + '\\n'\n","        board_str = board_str.replace('-1', 'O').replace('1', 'X')\n","        print(board_str)"]},{"cell_type":"code","execution_count":46,"metadata":{"id":"ZRYWA4n7j87D"},"outputs":[],"source":["class ResBlock(nn.Module):\n","    def __init__(self, num_hidden):\n","        super().__init__()\n","        self.conv1 = nn.Conv2d(num_hidden, num_hidden, kernel_size=3, padding=1)\n","        self.bn1 = nn.BatchNorm2d(num_hidden)\n","        self.conv2 = nn.Conv2d(num_hidden, num_hidden, kernel_size=3, padding=1)\n","        self.bn2 = nn.BatchNorm2d(num_hidden)\n","\n","    def forward(self, x):\n","        out = self.conv1(x)\n","        out = self.bn1(out)\n","        out = F.relu(out)\n","        out = self.conv2(out)\n","        out = self.bn2(out)\n","        out = out + x\n","        out = F.relu(out)\n","        return out\n","\n","class ResNet(nn.Module):\n","    def __init__(self, size, num_blocks, num_hidden, device):\n","        super().__init__()\n","\n","        self.device = device\n","        self.startBlock = nn.Sequential(\n","            nn.Conv2d(3, num_hidden, kernel_size=3, padding=1),\n","            nn.BatchNorm2d(num_hidden),\n","            nn.ReLU()\n","        )\n","\n","        self.backBone = nn.ModuleList(\n","            [ResBlock(num_hidden) for _ in range(num_blocks)]\n","        )\n","\n","        self.policyHead = nn.Sequential(\n","            nn.Conv2d(num_hidden, 32, kernel_size=3, padding=1),\n","            nn.BatchNorm2d(32),\n","            nn.ReLU(),\n","            nn.Flatten(),\n","            nn.Linear(size * size * 32, size * size)\n","        )\n","\n","        self.valueHead = nn.Sequential(\n","            nn.Conv2d(num_hidden, 3, kernel_size=3, padding=1),\n","            nn.BatchNorm2d(3),\n","            nn.ReLU(),\n","            nn.Flatten(),\n","            nn.Linear(3 * size * size, 1),\n","            nn.Tanh()\n","        )\n","\n","        self.to(device)\n","\n","    def forward(self, x):\n","        x = self.startBlock(x)\n","        for block in self.backBone:\n","            x = block(x)\n","        policy = self.policyHead(x)\n","        value = self.valueHead(x)\n","\n","        return policy, value"]},{"cell_type":"code","execution_count":47,"metadata":{"id":"x4Y3rOXaj87D"},"outputs":[],"source":["class Node:\n","    def __init__(self, game, args, state, parent=None, action=None, prior=0):\n","        self.game = game\n","        self.args = args\n","        self.state = state\n","        self.parent = parent\n","        self.action = action\n","        self.prior = prior\n","\n","        self.children = []\n","        self.visit_count = 0\n","        self.total_value = 0\n","\n","    def is_fully_expanded(self):\n","        return len(self.children) > 0\n","\n","    def select(self):\n","        best_child = None\n","        best_ucb = -np.inf\n","        for child in self.children:\n","            ucb = self.get_ucb(child)\n","            if ucb > best_ucb:\n","                best_ucb = ucb\n","                best_child = child\n","\n","        return best_child\n","\n","    def get_ucb(self, child):\n","        if child.visit_count == 0:\n","            q_value = 0\n","        else:\n","            q_value = 1 - (child.total_value / child.visit_count + 1) / 2\n","        return q_value + self.args['C'] * np.sqrt(self.visit_count) / (child.visit_count + 1) * child.prior\n","\n","    def expand(self, policy):\n","        for action, prob in enumerate(policy):\n","            if prob > 0:\n","                child_state = self.state.copy()\n","                child_state = self.game.get_next_state(child_state, action, PLAYER1)\n","                child_state = self.game.change_perspective(child_state, player=PLAYER2)\n","\n","                child = Node(self.game, self.args, child_state, self, action, prob)\n","                self.children.append(child)\n","\n","        return child\n","\n","    def backpropagate(self, value):\n","        self.visit_count += 1\n","        self.total_value += value\n","        if self.parent is not None:\n","            value = self.game.get_opponent_value(value)\n","            self.parent.backpropagate(value)\n","            \n","\n","class AlphaMCTS:\n","    def __init__(self, game, args, model):\n","        self.game = game\n","        self.args = args\n","        self.model = model\n","\n","    @torch.no_grad()\n","    def search(self, state):\n","        root = Node(self.game, self.args, state)\n","        for search in range(self.args['num_searches']):\n","            node = root\n","\n","            # selection\n","            while node.is_fully_expanded():\n","                node = node.select()\n","\n","            value, terminated = self.game.get_value_and_terminated(node.state, node.action)\n","            value = self.game.get_opponent_value(value)\n","\n","            if not terminated:\n","                policy, value = self.model(\n","                    torch.tensor(self.game.get_encoded_state(node.state), device=self.model.device).unsqueeze(0)\n","                )\n","                policy = torch.softmax(policy, axis=1).squeeze(0).detach().cpu().numpy()\n","                valid_moves = self.game.get_moves(node.state)\n","                policy = policy * valid_moves\n","                policy /= np.sum(policy)\n","\n","                value = value.item()\n","                node.expand(policy)\n","\n","            node.backpropagate(value)\n","\n","        action_probs = np.zeros(self.game.size * self.game.size)\n","        for child in root.children:\n","            action_probs[child.action] = child.visit_count\n","        action_probs = action_probs / np.sum(action_probs)\n","\n","        return action_probs\n","\n","\n","class TrainingMCTS:\n","    def __init__(self, game, args, model):\n","        self.game = game\n","        self.args = args\n","        self.model = model\n","\n","    @torch.no_grad()\n","    def search(self, states, self_play_games):\n","        policy, _ = self.model(\n","            torch.tensor(self.game.get_encoded_state(states), device=self.model.device)\n","        )\n","        policy = torch.softmax(policy, axis=1).cpu().numpy()\n","        \n","        for i, game in enumerate(self_play_games):\n","            game_policy = policy[i]\n","            valid_moves = self.game.get_moves(states[i])\n","            game_policy *= valid_moves\n","            game_policy /= np.sum(game_policy)\n","            \n","            game.root = Node(self.game, self.args, states[i])\n","            game.root.expand(game_policy)\n","        \n","        for search in range(self.args['num_searches']):\n","            for game in self_play_games:\n","                game.node = None\n","                node = game.root\n","\n","                while node.is_fully_expanded():\n","                    node = node.select()\n","\n","                value, terminated = self.game.get_value_and_terminated(node.state, node.action)\n","                value = self.game.get_opponent_value(value)\n","\n","                if terminated:\n","                    node.backpropagate(value)\n","                else:\n","                    game.node = node\n","                    \n","            expandable_games = [idx for idx in range(len(self_play_games)) if self_play_games[idx].node is not None]\n","            if len(expandable_games) > 0:\n","                states = np.stack([self_play_games[idx].node.state for idx in expandable_games])\n","                policy, value = self.model(\n","                    torch.tensor(self.game.get_encoded_state(states), device=self.model.device)\n","                )\n","                policy = torch.softmax(policy, axis=1).detach().cpu().numpy()\n","                value = value.cpu().numpy()\n","                \n","            for i, idx in enumerate(expandable_games):\n","                node = self_play_games[idx].node\n","                self_play_policy, self_play_value = policy[i], value[i]\n","                \n","                valid_moves = self.game.get_moves(node.state)\n","                self_play_policy = self_play_policy * valid_moves\n","                self_play_policy /= np.sum(self_play_policy)\n","                node.expand(self_play_policy)\n","                node.backpropagate(self_play_value)"]},{"cell_type":"code","execution_count":48,"metadata":{"id":"51d6OfDuj87E"},"outputs":[],"source":["class SelfPlayGame:\n","    def __init__(self, game):\n","        self.state = game.get_initial_state()\n","        self.memory = []\n","        self.root = None\n","        self.node = None\n","\n","class AlphaZero:\n","    def __init__(self, model, optimizer, game, args):\n","        self.model = model\n","        self.optimizer = optimizer\n","        self.game = game\n","        self.args = args\n","        self.mcts = TrainingMCTS(game, args, model)\n","\n","    def self_play(self):\n","        return_memory = []\n","        player = PLAYER1\n","        self_paly_games = [SelfPlayGame(self.game) for _ in range(self.args['num_parallel_games'])]\n","\n","        while len(self_paly_games) > 0:\n","            states = np.stack([game.state for game in self_paly_games])\n","            neutral_states = self.game.change_perspective(states, player)\n","            self.mcts.search(neutral_states, self_paly_games)\n","            \n","            for i in range(len(self_paly_games))[::-1]:\n","                game = self_paly_games[i]\n","                \n","                action_probs = np.zeros(self.game.size * self.game.size)\n","                for child in game.root.children:\n","                    action_probs[child.action] = child.visit_count\n","                action_probs = action_probs / np.sum(action_probs)\n","\n","                game.memory.append((game.root.state, action_probs, player))\n","                action = np.random.choice(self.game.size * self.game.size, p=action_probs)\n","                game.state = self.game.get_next_state(game.state, action, player)\n","                value, terminated = self.game.get_value_and_terminated(game.state, action)\n","                if terminated:\n","                    for state, action_probs, player in game.memory:\n","                        outcome = value if player == PLAYER1 else self.game.get_opponent_value(value)\n","                        return_memory.append((self.game.get_encoded_state(state), action_probs, outcome))\n","                    del self_paly_games[i]\n","\n","            player = self.game.get_opponent(player)\n","\n","        return return_memory\n","\n","\n","    def train(self, memory):\n","        random.shuffle(memory)\n","        for batch_index in range(0, len(memory), self.args['batch_size']):\n","            batch = memory[batch_index:min(len(memory) - 1, batch_index) + self.args['batch_size']]\n","            states, policy_targets, value_targets = zip(*batch)\n","\n","            states, policy_targets, value_targets = np.array(states), np.array(policy_targets), np.array(value_targets).reshape(-1, 1)\n","            states = torch.tensor(states, dtype=torch.float32, device=self.model.device)\n","            policy_targets = torch.tensor(policy_targets, dtype=torch.float32, device=self.model.device)\n","            value_targets = torch.tensor(value_targets, dtype=torch.float32, device=self.model.device)\n","\n","            out_policy, out_value = self.model(states)\n","\n","            policy_loss = F.cross_entropy(out_policy, policy_targets)\n","            value_loss = F.mse_loss(out_value, value_targets)\n","            loss = policy_loss + value_loss\n","\n","            self.optimizer.zero_grad()\n","            loss.backward()\n","            self.optimizer.step()\n","\n","    def learn(self):\n","        for iteration in trange(self.args['num_iterations']):\n","            memory = []\n","\n","            self.model.eval()\n","            for play_iteration in trange(self.args['num_self_play_iterations'] // self.args['num_parallel_games']):\n","                memory += self.self_play()\n","\n","            self.model.train()\n","            for epoch in range(self.args['num_epochs']):\n","                self.train(memory)\n","\n","            torch.save(self.model.state_dict(), f'{model_path}/model_{iteration}.pt')\n","            torch.save(self.optimizer.state_dict(), f'{optimizer_path}/optimizer_{iteration}.pt')"]},{"cell_type":"code","execution_count":49,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":118,"referenced_widgets":["493696a08b5d40b3b12d1f6eaaffe458","bc5401e642aa4457beb750f3712b7cba","6b4ea5e95ef448118ea401bfc90cd4a4","a648b52e5b3b4244a6266e44c71d2e2b","f7cd3d1660b04a43a2091b3eeeb6f0b3","d237ee9cbd1442b2a27afab6500b9ab3","7f5bb95122be4f1eb37d1ad4efbd7591","5dd0f606a3f64abd80c415a641034667","c6a5d5f0607a4c8ba6e60025b0ba5082","ac5e6c49fbbd4a0fa1eaf72dbb363b1d","d34e5f9274644418b21f99d067e09251","998acd75d3644ad5ae75376ed2c44f33","1137c56f245b4ab5858c91e5d919c608","9a1c962d9edb4c848474ebb627342911","cddd0cbb0d8a416b876014f95e028c6b","5e24a48884ef46138cfb01e699a70d81","136680060d3943048b8b285b9576bf13","e8adff4236b7420d8e2347311cad0799","266422b38c92412387d8c5a5645748c2","d61c4636053b480b82baac1182d500cf","9f4f950d0fe74e1a9d6e3b1c32757bf1","973db2695b01442aaa79ebaba19fed1a","157335ebc84642c682c94e8d07c53136","0d7fdce8baf14f5b94fa0a836f438537"]},"executionInfo":{"elapsed":1244854,"status":"ok","timestamp":1716846904413,"user":{"displayName":"Karol Denst","userId":"00469011533726302230"},"user_tz":-120},"id":"oksHef6uj87E","outputId":"7aa4c1c4-9280-4494-b58d-b8f6d405ac69"},"outputs":[],"source":["game = Gomoku(BOARD_SIZE)\n","num_blocks = 4\n","num_hidden = 64\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","model = ResNet(game.size, num_blocks, num_hidden, device)\n","optimizer = torch.optim.Adam(model.parameters(), lr=0.001, weight_decay=1e-4)\n","args = {\n","    'C': 2,\n","    'num_searches': 100,\n","    'num_iterations': 3,\n","    'num_self_play_iterations': 50,\n","    'num_epochs': 4,\n","    'num_parallel_games': 10,\n","    'batch_size': 64,\n","}\n","\n","alphaZero = AlphaZero(model, optimizer, game, args)\n","alphaZero.learn()"]},{"cell_type":"code","execution_count":50,"metadata":{"id":"GNwmmpxrj87D"},"outputs":[{"name":"stdout","output_type":"stream","text":["X X X X . . . O O O\n","O . . . . . . . . .\n",". . . . . . . . . .\n",". . . . . . . . . .\n",". . . . . . . . . .\n",". . . . . . . . . .\n",". . . . . . . . . .\n",". . . . . . . . . .\n",". . . . . . . . . .\n",". . . . . . . . . .\n","\n","-0.04723739996552467 [0.0103578  0.00970338 0.01058222 0.0100747  0.01141027 0.0105678\n"," 0.00990483 0.00953831 0.00963808 0.01115351 0.00949116 0.00994829\n"," 0.00937633 0.00940629 0.01013227 0.0097519  0.01012508 0.01007334\n"," 0.01022144 0.01073315 0.00984519 0.01046297 0.01113496 0.01023424\n"," 0.01000845 0.01011145 0.01099296 0.00989436 0.01029754 0.01008002\n"," 0.01072739 0.00922658 0.01053139 0.00864276 0.00977337 0.00922227\n"," 0.01015358 0.01122097 0.0093124  0.00971397 0.00963458 0.00949532\n"," 0.01069457 0.0104562  0.00988056 0.01030751 0.00939743 0.01036398\n"," 0.00953191 0.00946094 0.0092448  0.01084625 0.00979741 0.00978874\n"," 0.01105653 0.00896729 0.01026165 0.00966641 0.00952491 0.00845617\n"," 0.01017531 0.0106033  0.00863069 0.00934892 0.00893388 0.01069284\n"," 0.00975362 0.01059754 0.01050983 0.00949054 0.00982238 0.01035404\n"," 0.00933236 0.01031064 0.0105548  0.00985195 0.00934166 0.01037824\n"," 0.01068476 0.00951219 0.01081681 0.00924679 0.01036769 0.01051986\n"," 0.0102155  0.00973108 0.00979472 0.00972666 0.01006668 0.00961938\n"," 0.00877751 0.00990624 0.00959895 0.01078161 0.01063476 0.0102876\n"," 0.00957749 0.01104567 0.01016219 0.00963315]\n"]}],"source":["game = Gomoku(BOARD_SIZE)\n","\n","state = game.get_initial_state()\n","actions = [0, 7, 1, 8, 2, 9, 3, 10]\n","player = PLAYER1\n","for action in actions:\n","    state = game.get_next_state(state, action, player)\n","    player = game.get_opponent(player)\n","\n","game.print(state)\n","\n","tensor_state = torch.tensor(game.get_encoded_state(state)).unsqueeze(0)\n","\n","model = ResNet(game.size, num_blocks, num_hidden, device)\n","model.load_state_dict(torch.load(f'{model_path}/model_2.pt'))\n","model.eval()\n","\n","policy, value = model(tensor_state)\n","value = value.item()\n","policy = torch.softmax(policy, axis=1).squeeze(0).detach().cpu().numpy()\n","\n","print(value, policy)"]},{"cell_type":"code","execution_count":51,"metadata":{"id":"oHk6O2Qwj87E"},"outputs":[{"name":"stdout","output_type":"stream","text":[". . . . . . . . . .\n",". . . . . . . . . .\n",". . . . . . . . . .\n",". . . . . . . . . .\n",". . . . . . . . . .\n",". . . . . . . . . .\n",". . . . . . . . . .\n",". . . . . . . . . .\n",". . . . . . . . . .\n",". . . . . . . . . .\n","\n","Valid moves: [(0, 0), (0, 1), (0, 2), (0, 3), (0, 4), (0, 5), (0, 6), (0, 7), (0, 8), (0, 9), (0, 10), (0, 11), (0, 12), (0, 13), (0, 14), (0, 15), (0, 16), (0, 17), (0, 18), (0, 19), (0, 20), (0, 21), (0, 22), (0, 23), (0, 24), (0, 25), (0, 26), (0, 27), (0, 28), (0, 29), (0, 30), (0, 31), (0, 32), (0, 33), (0, 34), (0, 35), (0, 36), (0, 37), (0, 38), (0, 39), (0, 40), (0, 41), (0, 42), (0, 43), (0, 44), (0, 45), (0, 46), (0, 47), (0, 48), (0, 49), (0, 50), (0, 51), (0, 52), (0, 53), (0, 54), (0, 55), (0, 56), (0, 57), (0, 58), (0, 59), (0, 60), (0, 61), (0, 62), (0, 63), (0, 64), (0, 65), (0, 66), (0, 67), (0, 68), (0, 69), (0, 70), (0, 71), (0, 72), (0, 73), (0, 74), (0, 75), (0, 76), (0, 77), (0, 78), (0, 79), (0, 80), (0, 81), (0, 82), (0, 83), (0, 84), (0, 85), (0, 86), (0, 87), (0, 88), (0, 89), (0, 90), (0, 91), (0, 92), (0, 93), (0, 94), (0, 95), (0, 96), (0, 97), (0, 98), (0, 99)]\n",". . . . . . . . . .\n",". . . . . . . . . .\n",". . . . . . . . . .\n",". . . . . . . . . .\n",". . . . . . . . . .\n",". . . . . X . . . .\n",". . . . . . . . . .\n",". . . . . . . . . .\n",". . . . . . . . . .\n",". . . . . . . . . .\n","\n",". . . . . . . . . O\n",". . . . . . . . . .\n",". . . . . . . . . .\n",". . . . . . . . . .\n",". . . . . . . . . .\n",". . . . . X . . . .\n",". . . . . . . . . .\n",". . . . . . . . . .\n",". . . . . . . . . .\n",". . . . . . . . . .\n","\n","Valid moves: [(0, 0), (0, 1), (0, 2), (0, 3), (0, 4), (0, 5), (0, 6), (0, 7), (0, 8), (0, 10), (0, 11), (0, 12), (0, 13), (0, 14), (0, 15), (0, 16), (0, 17), (0, 18), (0, 19), (0, 20), (0, 21), (0, 22), (0, 23), (0, 24), (0, 25), (0, 26), (0, 27), (0, 28), (0, 29), (0, 30), (0, 31), (0, 32), (0, 33), (0, 34), (0, 35), (0, 36), (0, 37), (0, 38), (0, 39), (0, 40), (0, 41), (0, 42), (0, 43), (0, 44), (0, 45), (0, 46), (0, 47), (0, 48), (0, 49), (0, 50), (0, 51), (0, 52), (0, 53), (0, 54), (0, 56), (0, 57), (0, 58), (0, 59), (0, 60), (0, 61), (0, 62), (0, 63), (0, 64), (0, 65), (0, 66), (0, 67), (0, 68), (0, 69), (0, 70), (0, 71), (0, 72), (0, 73), (0, 74), (0, 75), (0, 76), (0, 77), (0, 78), (0, 79), (0, 80), (0, 81), (0, 82), (0, 83), (0, 84), (0, 85), (0, 86), (0, 87), (0, 88), (0, 89), (0, 90), (0, 91), (0, 92), (0, 93), (0, 94), (0, 95), (0, 96), (0, 97), (0, 98), (0, 99)]\n",". . . . . . . . . O\n",". . . . . . . . . .\n",". . . . . . . . . .\n",". . . . . . . . . .\n",". . . . X . . . . .\n",". . . . . X . . . .\n",". . . . . . . . . .\n",". . . . . . . . . .\n",". . . . . . . . . .\n",". . . . . . . . . .\n","\n",". . . . . . . . . O\n",". . . . . . . . . .\n",". . . . . . . . . .\n",". . . . . . . O . .\n",". . . . X . . . . .\n",". . . . . X . . . .\n",". . . . . . . . . .\n",". . . . . . . . . .\n",". . . . . . . . . .\n",". . . . . . . . . .\n","\n","Valid moves: [(0, 0), (0, 1), (0, 2), (0, 3), (0, 4), (0, 5), (0, 6), (0, 7), (0, 8), (0, 10), (0, 11), (0, 12), (0, 13), (0, 14), (0, 15), (0, 16), (0, 17), (0, 18), (0, 19), (0, 20), (0, 21), (0, 22), (0, 23), (0, 24), (0, 25), (0, 26), (0, 27), (0, 28), (0, 29), (0, 30), (0, 31), (0, 32), (0, 33), (0, 34), (0, 35), (0, 36), (0, 38), (0, 39), (0, 40), (0, 41), (0, 42), (0, 43), (0, 45), (0, 46), (0, 47), (0, 48), (0, 49), (0, 50), (0, 51), (0, 52), (0, 53), (0, 54), (0, 56), (0, 57), (0, 58), (0, 59), (0, 60), (0, 61), (0, 62), (0, 63), (0, 64), (0, 65), (0, 66), (0, 67), (0, 68), (0, 69), (0, 70), (0, 71), (0, 72), (0, 73), (0, 74), (0, 75), (0, 76), (0, 77), (0, 78), (0, 79), (0, 80), (0, 81), (0, 82), (0, 83), (0, 84), (0, 85), (0, 86), (0, 87), (0, 88), (0, 89), (0, 90), (0, 91), (0, 92), (0, 93), (0, 94), (0, 95), (0, 96), (0, 97), (0, 98), (0, 99)]\n",". . . . . . . . . O\n",". . . . . . . . . .\n",". . . . . . . . . .\n",". . . X . . . O . .\n",". . . . X . . . . .\n",". . . . . X . . . .\n",". . . . . . . . . .\n",". . . . . . . . . .\n",". . . . . . . . . .\n",". . . . . . . . . .\n","\n",". . . . O . . . . O\n",". . . . . . . . . .\n",". . . . . . . . . .\n",". . . X . . . O . .\n",". . . . X . . . . .\n",". . . . . X . . . .\n",". . . . . . . . . .\n",". . . . . . . . . .\n",". . . . . . . . . .\n",". . . . . . . . . .\n","\n","Valid moves: [(0, 0), (0, 1), (0, 2), (0, 3), (0, 5), (0, 6), (0, 7), (0, 8), (0, 10), (0, 11), (0, 12), (0, 13), (0, 14), (0, 15), (0, 16), (0, 17), (0, 18), (0, 19), (0, 20), (0, 21), (0, 22), (0, 23), (0, 24), (0, 25), (0, 26), (0, 27), (0, 28), (0, 29), (0, 30), (0, 31), (0, 32), (0, 34), (0, 35), (0, 36), (0, 38), (0, 39), (0, 40), (0, 41), (0, 42), (0, 43), (0, 45), (0, 46), (0, 47), (0, 48), (0, 49), (0, 50), (0, 51), (0, 52), (0, 53), (0, 54), (0, 56), (0, 57), (0, 58), (0, 59), (0, 60), (0, 61), (0, 62), (0, 63), (0, 64), (0, 65), (0, 66), (0, 67), (0, 68), (0, 69), (0, 70), (0, 71), (0, 72), (0, 73), (0, 74), (0, 75), (0, 76), (0, 77), (0, 78), (0, 79), (0, 80), (0, 81), (0, 82), (0, 83), (0, 84), (0, 85), (0, 86), (0, 87), (0, 88), (0, 89), (0, 90), (0, 91), (0, 92), (0, 93), (0, 94), (0, 95), (0, 96), (0, 97), (0, 98), (0, 99)]\n",". . . . O . . . . O\n",". . . . . . . . . .\n",". . X . . . . . . .\n",". . . X . . . O . .\n",". . . . X . . . . .\n",". . . . . X . . . .\n",". . . . . . . . . .\n",". . . . . . . . . .\n",". . . . . . . . . .\n",". . . . . . . . . .\n","\n",". . . . O . . . . O\n",". . . . . . . . . .\n",". . X . . . . . . .\n",". . . X . . . O . .\n",". . . . X . . . . .\n",". . . . O X . . . .\n",". . . . . . . . . .\n",". . . . . . . . . .\n",". . . . . . . . . .\n",". . . . . . . . . .\n","\n","Valid moves: [(0, 0), (0, 1), (0, 2), (0, 3), (0, 5), (0, 6), (0, 7), (0, 8), (0, 10), (0, 11), (0, 12), (0, 13), (0, 14), (0, 15), (0, 16), (0, 17), (0, 18), (0, 19), (0, 20), (0, 21), (0, 23), (0, 24), (0, 25), (0, 26), (0, 27), (0, 28), (0, 29), (0, 30), (0, 31), (0, 32), (0, 34), (0, 35), (0, 36), (0, 38), (0, 39), (0, 40), (0, 41), (0, 42), (0, 43), (0, 45), (0, 46), (0, 47), (0, 48), (0, 49), (0, 50), (0, 51), (0, 52), (0, 53), (0, 56), (0, 57), (0, 58), (0, 59), (0, 60), (0, 61), (0, 62), (0, 63), (0, 64), (0, 65), (0, 66), (0, 67), (0, 68), (0, 69), (0, 70), (0, 71), (0, 72), (0, 73), (0, 74), (0, 75), (0, 76), (0, 77), (0, 78), (0, 79), (0, 80), (0, 81), (0, 82), (0, 83), (0, 84), (0, 85), (0, 86), (0, 87), (0, 88), (0, 89), (0, 90), (0, 91), (0, 92), (0, 93), (0, 94), (0, 95), (0, 96), (0, 97), (0, 98), (0, 99)]\n","Player 1 wins\n"]}],"source":["game = Gomoku(BOARD_SIZE)\n","player = PLAYER1\n","\n","args = {\n","    'C': 2,\n","    'num_searches': 100,\n","    'num_iterations': 3,\n","    'num_self_play_iterations': 50,\n","    'num_epochs': 4,\n","    'batch_size': 64,\n","}\n","model = ResNet(game.size, num_blocks, num_hidden, device)\n","model.load_state_dict(torch.load(f'{model_path}/model_2.pt', map_location=device))\n","model.eval()\n","mcts = AlphaMCTS(game, args, model)\n","\n","states = game.get_initial_state()\n","tiles = game.size * game.size\n","\n","while True:\n","    game.print(states)\n","    if player == PLAYER1:\n","        valid_moves = game.get_moves(states)\n","        print(\"Valid moves:\", [(i // tiles, i % tiles) for i in range(tiles) if valid_moves[i] == 1])\n","        user_input = input(\"Enter action: \")\n","        action = int(user_input.split(',')[0]) * game.size + int(user_input.split(',')[1])\n","\n","        if valid_moves[action] == 0:\n","            print(\"Invalid move\")\n","            continue\n","    else:\n","        neutral_state = game.change_perspective(states, player)\n","        mcts_action_probs = mcts.search(states)\n","        action = np.argmax(mcts_action_probs)\n","\n","\n","    states = game.get_next_state(states, action, player)\n","    value, terminated = game.get_value_and_terminated(states, action)\n","    if terminated:\n","        if value == 1:\n","            print(\"Player\", player, \"wins\")\n","        else:\n","            print(\"Draw\")\n","        break\n","\n","    player = game.get_opponent(player)"]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.9"},"widgets":{"application/vnd.jupyter.widget-state+json":{"1137c56f245b4ab5858c91e5d919c608":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_136680060d3943048b8b285b9576bf13","placeholder":"​","style":"IPY_MODEL_e8adff4236b7420d8e2347311cad0799","value":"  0%"}},"136680060d3943048b8b285b9576bf13":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"266422b38c92412387d8c5a5645748c2":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"493696a08b5d40b3b12d1f6eaaffe458":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_bc5401e642aa4457beb750f3712b7cba","IPY_MODEL_6b4ea5e95ef448118ea401bfc90cd4a4","IPY_MODEL_a648b52e5b3b4244a6266e44c71d2e2b"],"layout":"IPY_MODEL_f7cd3d1660b04a43a2091b3eeeb6f0b3"}},"5dd0f606a3f64abd80c415a641034667":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5e24a48884ef46138cfb01e699a70d81":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6b4ea5e95ef448118ea401bfc90cd4a4":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_5dd0f606a3f64abd80c415a641034667","max":3,"min":0,"orientation":"horizontal","style":"IPY_MODEL_c6a5d5f0607a4c8ba6e60025b0ba5082","value":3}},"7f5bb95122be4f1eb37d1ad4efbd7591":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"973db2695b01442aaa79ebaba19fed1a":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"998acd75d3644ad5ae75376ed2c44f33":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_1137c56f245b4ab5858c91e5d919c608","IPY_MODEL_9a1c962d9edb4c848474ebb627342911","IPY_MODEL_cddd0cbb0d8a416b876014f95e028c6b"],"layout":"IPY_MODEL_5e24a48884ef46138cfb01e699a70d81"}},"9a1c962d9edb4c848474ebb627342911":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"","description":"","description_tooltip":null,"layout":"IPY_MODEL_266422b38c92412387d8c5a5645748c2","max":50,"min":0,"orientation":"horizontal","style":"IPY_MODEL_d61c4636053b480b82baac1182d500cf","value":0}},"9f4f950d0fe74e1a9d6e3b1c32757bf1":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a648b52e5b3b4244a6266e44c71d2e2b":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ac5e6c49fbbd4a0fa1eaf72dbb363b1d","placeholder":"​","style":"IPY_MODEL_d34e5f9274644418b21f99d067e09251","value":" 3/3 [1:43:27&lt;00:00, 2043.28s/it]"}},"ac5e6c49fbbd4a0fa1eaf72dbb363b1d":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"bc5401e642aa4457beb750f3712b7cba":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d237ee9cbd1442b2a27afab6500b9ab3","placeholder":"​","style":"IPY_MODEL_7f5bb95122be4f1eb37d1ad4efbd7591","value":"100%"}},"c6a5d5f0607a4c8ba6e60025b0ba5082":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"cddd0cbb0d8a416b876014f95e028c6b":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_9f4f950d0fe74e1a9d6e3b1c32757bf1","placeholder":"​","style":"IPY_MODEL_973db2695b01442aaa79ebaba19fed1a","value":" 0/50 [00:00&lt;?, ?it/s]"}},"d237ee9cbd1442b2a27afab6500b9ab3":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d34e5f9274644418b21f99d067e09251":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"d61c4636053b480b82baac1182d500cf":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"e8adff4236b7420d8e2347311cad0799":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"f7cd3d1660b04a43a2091b3eeeb6f0b3":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}}}}},"nbformat":4,"nbformat_minor":0}
